{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from Features import FeatureEngineer\n",
    "from Environment import TradingEnvironment , random_policy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexa\\Documents\\Visual Studio Code\\Reinforcement-Learning-Project\\./src\\Features.py:34: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  self.df['Date']=pd.to_datetime(self.df['Date'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaz = pd.read_csv('data/Dutch TTF Natural Gas Futures - Données Historiques (1).csv')\n",
    "fe_gaz = FeatureEngineer(gaz)\n",
    "fe_gaz.apply_preprocessing()\n",
    "gaz_df = fe_gaz.df\n",
    "\n",
    "data = gaz_df[\"Dernier\"]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = TradingEnvironment(data)\n",
    "\n",
    "env.observation_space.shape[0]\n",
    "env.action_space.n\n",
    "\n",
    "env.index_loc\n",
    "env.index_step\n",
    "env.index_loc + env.index_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>price</th>\n",
       "      <th>position</th>\n",
       "      <th>action</th>\n",
       "      <th>new_balance</th>\n",
       "      <th>new_price</th>\n",
       "      <th>new_position</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.840</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>6.165</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>6.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.865</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.945</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000.000</td>\n",
       "      <td>5.945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>6.095</td>\n",
       "      <td>0</td>\n",
       "      <td>10000.000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>9646.523</td>\n",
       "      <td>84.015</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9646.523</td>\n",
       "      <td>90.925</td>\n",
       "      <td>13</td>\n",
       "      <td>10828.548</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>9646.523</td>\n",
       "      <td>90.925</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9555.598</td>\n",
       "      <td>93.985</td>\n",
       "      <td>14</td>\n",
       "      <td>10871.388</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>9555.598</td>\n",
       "      <td>93.985</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>9461.613</td>\n",
       "      <td>93.300</td>\n",
       "      <td>15</td>\n",
       "      <td>10861.113</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>9461.613</td>\n",
       "      <td>93.300</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9368.313</td>\n",
       "      <td>87.772</td>\n",
       "      <td>16</td>\n",
       "      <td>10772.665</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>9368.313</td>\n",
       "      <td>87.772</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>9280.541</td>\n",
       "      <td>93.146</td>\n",
       "      <td>17</td>\n",
       "      <td>10864.023</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       balance   price  position  action  new_balance  new_price  \\\n",
       "0    10000.000   5.105         0       0    10000.000      5.840   \n",
       "1    10000.000   5.840         0       0    10000.000      6.165   \n",
       "2    10000.000   6.165         0       0    10000.000      5.865   \n",
       "3    10000.000   5.865         0       0    10000.000      5.945   \n",
       "4    10000.000   5.945         0       0    10000.000      6.095   \n",
       "..         ...     ...       ...     ...          ...        ...   \n",
       "355   9646.523  84.015        13       0     9646.523     90.925   \n",
       "356   9646.523  90.925        13       1     9555.598     93.985   \n",
       "357   9555.598  93.985        14       1     9461.613     93.300   \n",
       "358   9461.613  93.300        15       1     9368.313     87.772   \n",
       "359   9368.313  87.772        16       1     9280.541     93.146   \n",
       "\n",
       "     new_position     reward   done  \n",
       "0               0  10000.000  False  \n",
       "1               0  10000.000  False  \n",
       "2               0  10000.000  False  \n",
       "3               0  10000.000  False  \n",
       "4               0  10000.000  False  \n",
       "..            ...        ...    ...  \n",
       "355            13  10828.548  False  \n",
       "356            14  10871.388  False  \n",
       "357            15  10861.113  False  \n",
       "358            16  10772.665  False  \n",
       "359            17  10864.023   True  \n",
       "\n",
       "[360 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtest_history = env.run_backtest(random_policy)\n",
    "\n",
    "history_df = pd.DataFrame(backtest_history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.memory, batch_size))\n",
    "        return np.array(state), action, reward, np.array(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = F.softmax(self.fc3(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "LR = 1e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_observations = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "state = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(num_observations, num_actions).to(device)\n",
    "target_net = DQN(num_observations, num_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "replay_memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action(state, index_step):\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * np.exp(-1.0 * index_step / EPS_DECAY)\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "            # torch.Size([1, 1])\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "        # torch.Size([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:58<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "def train_dqn(num_episodes):\n",
    "\n",
    "    policy_net.train()\n",
    "    history = []\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "\n",
    "        state = torch.tensor(env.reset(), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        # torch.Size([1, 3])\n",
    "        rewards = []\n",
    "\n",
    "        for t in range(env.max_steps):\n",
    "\n",
    "            action = epsilon_greedy_action(state, t) # torch.Size([1, 1])\n",
    "            next_state, reward, done, _ = env.step(action.item())\n",
    "            next_state = torch.tensor(next_state, dtype=torch.float32, device=device).unsqueeze(0) # torch.Size([1, 3])\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "\n",
    "            replay_memory.push(state, action, reward, next_state, done)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            if len(replay_memory) > BATCH_SIZE:\n",
    "\n",
    "                states, actions, rewards, next_states, dones = replay_memory.sample(BATCH_SIZE)\n",
    "\n",
    "                states = torch.tensor(states, dtype=torch.float32)\n",
    "                actions = torch.tensor(actions, dtype=torch.long)\n",
    "                rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "                next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "                dones = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "                states = states.squeeze(1) \n",
    "                # torch.Size([batch_size, num_actions])\n",
    "                next_states = states.squeeze(1)\n",
    "                # torch.Size([batch_size, num_actions])\n",
    "                actions = actions.unsqueeze(1)\n",
    "                # torch.Size([batch_size, 1])\n",
    "\n",
    "                state_action_values = policy_net(states).gather(1, actions)\n",
    "                # torch.Size([batch_size, 1])\n",
    "                next_state_values = target_net(next_states).max(1)[0].detach()\n",
    "                # torch.Size([batch_size, num_actions])\n",
    "                expected_state_action_values = rewards + (1 - dones) * GAMMA * next_state_values\n",
    "\n",
    "                criterion = nn.SmoothL1Loss()\n",
    "                loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        if episode % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        \n",
    "        history.append(env.info)\n",
    "\n",
    "        # print(f\"Episode: {episode+1}, End Reward: {balance + price*pos}\")\n",
    "\n",
    "    return history\n",
    "    \n",
    "# Train the DQN\n",
    "history = train_dqn(num_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>price</th>\n",
       "      <th>position</th>\n",
       "      <th>action</th>\n",
       "      <th>new_balance</th>\n",
       "      <th>new_price</th>\n",
       "      <th>new_position</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8361.528</td>\n",
       "      <td>55.425</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8361.528</td>\n",
       "      <td>55.156</td>\n",
       "      <td>18</td>\n",
       "      <td>9354.336</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9500.435</td>\n",
       "      <td>11.420</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>9511.855</td>\n",
       "      <td>11.860</td>\n",
       "      <td>25</td>\n",
       "      <td>9808.355</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937.367</td>\n",
       "      <td>99.425</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>8937.367</td>\n",
       "      <td>103.820</td>\n",
       "      <td>18</td>\n",
       "      <td>10806.127</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9483.255</td>\n",
       "      <td>12.710</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>9483.255</td>\n",
       "      <td>12.245</td>\n",
       "      <td>27</td>\n",
       "      <td>9813.870</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9810.737</td>\n",
       "      <td>79.075</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9810.737</td>\n",
       "      <td>72.585</td>\n",
       "      <td>13</td>\n",
       "      <td>10754.342</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9770.030</td>\n",
       "      <td>14.000</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>9770.030</td>\n",
       "      <td>14.240</td>\n",
       "      <td>27</td>\n",
       "      <td>10154.510</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9787.320</td>\n",
       "      <td>19.285</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>9787.320</td>\n",
       "      <td>18.990</td>\n",
       "      <td>22</td>\n",
       "      <td>10205.100</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9915.618</td>\n",
       "      <td>82.465</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9915.618</td>\n",
       "      <td>83.400</td>\n",
       "      <td>6</td>\n",
       "      <td>10416.018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9600.580</td>\n",
       "      <td>50.835</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9600.580</td>\n",
       "      <td>50.170</td>\n",
       "      <td>13</td>\n",
       "      <td>10252.790</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8541.435</td>\n",
       "      <td>51.705</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>8541.435</td>\n",
       "      <td>52.385</td>\n",
       "      <td>16</td>\n",
       "      <td>9379.595</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     balance   price  position  action  new_balance  new_price  new_position  \\\n",
       "0   8361.528  55.425        18       0     8361.528     55.156            18   \n",
       "1   9500.435  11.420        26      -1     9511.855     11.860            25   \n",
       "2   8937.367  99.425        18       0     8937.367    103.820            18   \n",
       "3   9483.255  12.710        27       0     9483.255     12.245            27   \n",
       "4   9810.737  79.075        13       0     9810.737     72.585            13   \n",
       "..       ...     ...       ...     ...          ...        ...           ...   \n",
       "95  9770.030  14.000        27       0     9770.030     14.240            27   \n",
       "96  9787.320  19.285        22       0     9787.320     18.990            22   \n",
       "97  9915.618  82.465         6       0     9915.618     83.400             6   \n",
       "98  9600.580  50.835        13       0     9600.580     50.170            13   \n",
       "99  8541.435  51.705        16       0     8541.435     52.385            16   \n",
       "\n",
       "       reward  done  \n",
       "0    9354.336  True  \n",
       "1    9808.355  True  \n",
       "2   10806.127  True  \n",
       "3    9813.870  True  \n",
       "4   10754.342  True  \n",
       "..        ...   ...  \n",
       "95  10154.510  True  \n",
       "96  10205.100  True  \n",
       "97  10416.018  True  \n",
       "98  10252.790  True  \n",
       "99   9379.595  True  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(history)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10125.073110000003"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reward.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dqn(num_episodes):\n",
    "\n",
    "    policy_net.eval()\n",
    "    history = []\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "\n",
    "        state = torch.tensor(env.reset(), dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        rewards = []\n",
    "\n",
    "        for t in range(env.max_steps):\n",
    "\n",
    "            action = policy_net(state).max(1).indices.view(1, 1)\n",
    "            next_state, reward, done, _ = env.step(action.item())\n",
    "            next_state = torch.tensor(next_state, dtype=torch.float32, device=device).unsqueeze(0) # torch.Size([1, 3])\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        history.append(env.info)\n",
    "\n",
    "    return history\n",
    "    \n",
    "# Train the DQN\n",
    "history = eval_dqn(num_episodes=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
